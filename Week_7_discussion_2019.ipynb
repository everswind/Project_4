{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "Basic Datastructure:\n",
    "1. Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). \n",
    "2. DataFrame is a 2-dimensional labeled data structure with columns of potentially different types\n",
    "3. Panel is a somewhat less-used, but still important container for 3-dimensional data. The term panel data is derived from econometrics and is partially responsible for the name pandas: pan(el)-da(ta)-s. \n",
    "\n",
    "#### Examples:\n",
    "DataFrame:(Quick tutorial:https://www.tutorialspoint.com/python_pandas/python_pandas_dataframe.htm)\n",
    "1. create dataframe\n",
    "2. select and index\n",
    "3. convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index by column numbers:\n",
      "           B         C\n",
      "0 -0.273562 -0.485425\n",
      "1 -1.658433 -0.015363\n",
      "2 -0.274297  0.294145\n",
      "3 -0.051012  0.227535\n",
      "4 -2.296558 -0.805188\n",
      "index by column names: one column\n",
      " 0    0.266964\n",
      "1   -1.273495\n",
      "2   -0.286125\n",
      "3    0.959914\n",
      "4   -0.747683\n",
      "Name: A, dtype: float64\n",
      "index by column names: multiple columns\n",
      "           A         B\n",
      "0  0.266964 -0.273562\n",
      "1 -1.273495 -1.658433\n",
      "2 -0.286125 -0.274297\n",
      "3  0.959914 -0.051012\n",
      "4 -0.747683 -2.296558\n",
      "select rows by conditions\n",
      ":           A         B         C         D\n",
      "1 -1.273495 -1.658433 -0.015363 -2.241884\n",
      "2 -0.286125 -0.274297  0.294145 -0.450299\n",
      "4 -0.747683 -2.296558 -0.805188 -0.865138\n",
      "5 -0.194597 -0.355680 -0.021988  0.562281\n",
      "7 -0.415250 -0.911368  1.373268 -0.287063\n",
      "access dataframe values \n",
      ": <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#df=pd.read_csv('clean_dataset.csv', sep=',',header='infer')\n",
    "df = pd.DataFrame(np.random.randn(8, 4), columns = ['A', 'B', 'C', 'D'])\n",
    "#print df['A']< 0\n",
    "#print \"subset:\"\n",
    "#print df[df['A']< 0]\n",
    "## index by column numbers\n",
    "print(\"index by column numbers:\\n\", df.iloc[:,1:3].head())\n",
    "## index by column names:\n",
    "print(\"index by column names: one column\\n\", df.loc[:,'A'].head())\n",
    "print(\"index by column names: multiple columns\\n\", df[['A','B']].head())\n",
    "## select rows by conditions\n",
    "\n",
    "tmp_data = df[df['A'] < 0]\n",
    "print( \"select rows by conditions\\n:\", tmp_data)\n",
    "## access dataframe values\n",
    "print( \"access dataframe values \\n:\",  type(tmp_data.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering:\n",
    "ref: \n",
    "https://www.youtube.com/watch?v=LMlzHfJPvjI&list=PL7tqo8Xk0expKfOuKz9AWWQ0rqIhtjjfP&index=16\n",
    "\n",
    "From raw data to useful features\n",
    "1. Feature extraction, preprocessing\n",
    "2. Feature selection\n",
    "    1. Remove useless features\n",
    "    2. sklearn: statistics, correlation, model_based\n",
    "    2. Feature Generation\n",
    "\n",
    "E.g. Automatic Feature Generation:\n",
    "1. multiplicative interactions\n",
    "2. Function transformation: $x^2, sqrt(x), ln(x)$\n",
    "3. Automated Threshold Selection:\n",
    "    1. Turn a numerical variable into a binary\n",
    "    2. Find a cut off point automatically\n",
    "    \n",
    "Automatic Feature Selectionï¼š\n",
    "1. Correlation Filtering:\n",
    "    How to choose among those correlated features? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature preprocessing\n",
    "1. scaling\n",
    "     1. to [0,1]:\n",
    "        sklearn.preprocessing.MinMaxScaler\n",
    "     2. to mean=0,std=1:\n",
    "         sklearn.preprocessing.StandardScaler\n",
    "     3. http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
    "2. outlier\n",
    "3. encoding\n",
    "     1. rank: set spaces between sorted values equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature encoding\n",
    "reference: https://zh.coursera.org/learn/competitive-data-science/lecture/wckTQ/datetime-and-coordinates\n",
    "#### Type of features\n",
    "1. Numerical features\n",
    "2. Categorical features\n",
    "3. Ordinal features\n",
    "4. Datetime and coordiantes\n",
    "5. Handling missing values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample code for one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4]\n",
      "[0 2 5 9]\n",
      "  (0, 7)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (1, 5)\t1.0\n",
      "  (1, 3)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 5)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 6)\t1.0\n",
      "  (3, 2)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "[array([0, 1]), array([0, 1, 2]), array([1, 2, 3])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function n_values_ is deprecated; The ``n_values_`` attribute was deprecated in version 0.20 and will be removed 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function feature_indices_ is deprecated; The ``feature_indices_`` attribute was deprecated in version 0.20 and will be removed 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "test_ft = [[0, 0, 3], [1, 1, 1], [0, 2, 1], [1, 0, 2]]\n",
    "enc.fit(test_ft)\n",
    "print(enc.n_values_)\n",
    "print(enc.feature_indices_)\n",
    "print(enc.transform(test_ft))\n",
    "\n",
    "###You are recommended to set categories='auto' (the new version)\n",
    "enc2 = OneHotEncoder(categories='auto')\n",
    "enc2.fit(test_ft)\n",
    "#print(enc2.n_values_)\n",
    "#print(enc2.feature_indices_)\n",
    "print(enc2.categories_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### using pandas \n",
    "import pandas  as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "path = './'\n",
    "df = pd.read_csv(path+'insurance_data.csv')\n",
    "ft0 = ['ft1','ft2','ft3','ft4', 'ft5', 'ft6']\n",
    "categorical_columns = ft0\n",
    "df_encode = pd.get_dummies(data = df, prefix = None, prefix_sep='_',\\\n",
    "                           columns = categorical_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform columns of dataframe separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(['northeast', 'northwest', 'southeast', 'southwest'], dtype=object)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(),['ft1', 'ft2']),\n",
    "    (OneHotEncoder(sparse=False), ['ft6']),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ft_res = preprocess.fit_transform(df[ft0])\n",
    "## access one intermedia step model\n",
    "preprocess.transformers_[1][1].categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction for features importance in the Random Forest\n",
    "ref: https://zh.coursera.org/learn/python-machine-learning/lecture/lF9QN/random-forests\n",
    "<img src=rf.png>\n",
    "\n",
    "1. Randomized bootstrap copies\n",
    "2. Randomized feature splits\n",
    "3. predictions for regression task : mean of tree predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'northeast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be97f807cb25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mforest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtree1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m dot_data = tree.export_graphviz(tree1, out_file=None, feature_names=feature_list0, \n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'northeast'"
     ]
    }
   ],
   "source": [
    "# visualize the random forest\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import graphviz \n",
    "# best tree: 3 features, 20 estimators,\n",
    "RANDOM_STATE = 42\n",
    "forest1 =  RandomForestRegressor(oob_score=True,\n",
    "                               max_features=3,max_depth=4,\n",
    "                               random_state=RANDOM_STATE)\n",
    "\n",
    "forest1.set_params(n_estimators=20)\n",
    "X = df.iloc[:200,0:6].values\n",
    "y = df.iloc[:200,6].values\n",
    "\n",
    "\n",
    "forest1.fit(X, y)\n",
    "tree1 = forest1.estimators_[1]\n",
    "dot_data = tree.export_graphviz(tree1, out_file=None, feature_names=feature_list0, \n",
    "                                class_names=\"charges\",   filled=True, rounded=True,  special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('random_forest.png', view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
